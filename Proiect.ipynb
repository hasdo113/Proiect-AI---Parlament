{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0c0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold \n",
    "import unicodedata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data_path = ''\n",
    "train_data_df = pd.read_csv(os.path.join(train_data_path, 'train_data.csv'))\n",
    "\n",
    "test_data_path = ''\n",
    "test_data_df = pd.read_csv(os.path.join(test_data_path, 'test_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ef8590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dansk</td>\n",
       "      <td>\\nDette er et fremragende initiativ, og jeg st...</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dansk</td>\n",
       "      <td>\\nHr. formand, jeg er sikker på, at alle her e...</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dansk</td>\n",
       "      <td>\\nHr. formand, folk på den nordlige halvkugle ...</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dansk</td>\n",
       "      <td>\\nHr. formand, med forbehold af nogle få ændri...</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dansk</td>\n",
       "      <td>\\n\\n   - Hr. formand, jeg må protestere mod de...</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41565</th>\n",
       "      <td>Nederlands</td>\n",
       "      <td>\\nMijnheer de Voorzitter, juridisch gezien is ...</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41566</th>\n",
       "      <td>Nederlands</td>\n",
       "      <td>\\n\\n   .  Mijnheer de Voorzitter, het is niet ...</td>\n",
       "      <td>Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41567</th>\n",
       "      <td>Nederlands</td>\n",
       "      <td>\\nAls afgevaardigde van Ierland, het 'voedsele...</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41568</th>\n",
       "      <td>Nederlands</td>\n",
       "      <td>\\nMijnheer de Voorzitter, het is niet onterech...</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41569</th>\n",
       "      <td>Nederlands</td>\n",
       "      <td>\\n\\n   - Stelt u zich voor dat een ander wetge...</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41570 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         language                                               text     label\n",
       "0           dansk  \\nDette er et fremragende initiativ, og jeg st...   Ireland\n",
       "1           dansk  \\nHr. formand, jeg er sikker på, at alle her e...   Ireland\n",
       "2           dansk  \\nHr. formand, folk på den nordlige halvkugle ...   England\n",
       "3           dansk  \\nHr. formand, med forbehold af nogle få ændri...   England\n",
       "4           dansk  \\n\\n   - Hr. formand, jeg må protestere mod de...   England\n",
       "...           ...                                                ...       ...\n",
       "41565  Nederlands  \\nMijnheer de Voorzitter, juridisch gezien is ...   England\n",
       "41566  Nederlands  \\n\\n   .  Mijnheer de Voorzitter, het is niet ...  Scotland\n",
       "41567  Nederlands  \\nAls afgevaardigde van Ierland, het 'voedsele...   Ireland\n",
       "41568  Nederlands  \\nMijnheer de Voorzitter, het is niet onterech...   England\n",
       "41569  Nederlands  \\n\\n   - Stelt u zich voor dat een ander wetge...   Ireland\n",
       "\n",
       "[41570 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9384c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n   Hr. formand, selv om vi i høj grad symp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n   Quiero dejar constancia de mi apoyo a e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n   . – El comercio ilegal de riñones human...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nSignor Presidente, per introdurre una nota d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nJeg stemte for meddelelsen af decharge til f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13855</th>\n",
       "      <td>\\nschriftlich. - Dieser Bericht handelt von wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13856</th>\n",
       "      <td>\\n\\n   Signor Presidente, desidero ringraziare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13857</th>\n",
       "      <td>\\n. (EN) Ich unterstütze den Bericht von Herrn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13858</th>\n",
       "      <td>\\n\\n   – Mijnheer de Voorzitter, ik ben verheu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13859</th>\n",
       "      <td>\\nJeg stemte for at bekræfte hr. Trichet som f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13860 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      \\n\\n   Hr. formand, selv om vi i høj grad symp...\n",
       "1      \\n\\n   Quiero dejar constancia de mi apoyo a e...\n",
       "2      \\n\\n   . – El comercio ilegal de riñones human...\n",
       "3      \\nSignor Presidente, per introdurre una nota d...\n",
       "4      \\nJeg stemte for meddelelsen af decharge til f...\n",
       "...                                                  ...\n",
       "13855  \\nschriftlich. - Dieser Bericht handelt von wi...\n",
       "13856  \\n\\n   Signor Presidente, desidero ringraziare...\n",
       "13857  \\n. (EN) Ich unterstütze den Bericht von Herrn...\n",
       "13858  \\n\\n   – Mijnheer de Voorzitter, ik ben verheu...\n",
       "13859  \\nJeg stemte for at bekræfte hr. Trichet som f...\n",
       "\n",
       "[13860 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ac5d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ireland' 'England' 'Scotland']\n",
      "{'Ireland': 0, 'England': 1, 'Scotland': 2}\n",
      "{0: 'Ireland', 1: 'England', 2: 'Scotland'}\n"
     ]
    }
   ],
   "source": [
    "etichete_unice = train_data_df['label'].unique()\n",
    "print(etichete_unice)\n",
    "\n",
    "label2id = {}\n",
    "id2label = {}\n",
    "for idx, eticheta in enumerate(etichete_unice):\n",
    "    label2id[eticheta]=idx\n",
    "    id2label[idx]=eticheta\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67598e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for eticheta in train_data_df['label']:\n",
    "    labels.append(label2id[eticheta])\n",
    "labels=np.array(labels)\n",
    "\n",
    "# Nu uita sa modificam inapoi\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece3fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_data_df['label'].apply(lambda etich: label2id[etich])\n",
    "labels = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ff6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# luat in calcul cuvintele functionale, pot creste sau scadea acuratetea\n",
    "# in cazul de fata, cuvintele functionale (stop words) indica elemente de gramatica\n",
    "# care sunt specifice textelor de la Scotieni, Englezi, Irlandezi\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopw=stopwords.words('danish')+stopwords.words('dutch')+stopwords.words('spanish')+stopwords.words('german')+stopwords.words('italian')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0017960e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def proceseaza(text):\n",
    "    \"\"\"Functie simpla de procesare a textului.\n",
    "    Sugestii:\n",
    "    - cum procesati \\n new lines? (vezi functia strip())  ✔️\n",
    "    - cum procesati empty token '' ✔️\n",
    "    - puteti introduce un tokenizator din nltk ?✔️\n",
    "    - puteti elimina sau pastra doar stop-words ?✔️\n",
    "    \"\"\"\n",
    "    text = re.sub(\"[-.,;:!?\\\"\\'\\/()_*=~@#$^&`]\", \" \", text) #Eliminare caracere speciale I\n",
    "    text = re.sub(\"[0-9+–%]\", \" \", text) # Eliminare caractere speciale II\n",
    "    text = text.replace('\\n',' ') # Replace de /n-uri\n",
    "    pattern = r\"((?<=^)|(?<= )).((?=$)|(?= ))\" #Scotea caractere cu un singur caracter : a b c d etc... / Este Regexul\n",
    "    text=re.sub(\"\\s+\", \" \", re.sub(pattern, '', text).strip()) # Scoaterea efectiva\n",
    "    text2=unicodedata.normalize(\"NFKD\", text) #Normalizare pt eroare de un cuvant in most common\n",
    "    text_in_cuvinte = text2.strip('  ').split(' ')\n",
    "    text_in_cuvinte = list(filter(None, text_in_cuvinte))#Scoaterea de spatii goale\n",
    "    text_in_cuvinte2=[]\n",
    "    text_cuvinte=[]\n",
    "    for i in  text_in_cuvinte:\n",
    "            text_cuvinte.append(i.lower())\n",
    "    for i in text_cuvinte:\n",
    "        if i not in stopw :\n",
    "            text_in_cuvinte2.append(i)\n",
    "    return text_in_cuvinte2\n",
    "  \n",
    "\n",
    "\n",
    "data = train_data_df['text'].apply(proceseaza)\n",
    "\n",
    "\n",
    "\n",
    "data2=test_data_df['text'].apply(proceseaza)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71339d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('på', 26094), ('für', 21854), ('eu', 17142), ('we', 15756), ('europa', 14991), ('presidente', 14734), ('europea', 13318), ('wij', 12340), ('parlamento', 11493), ('moeten', 10083), ('hr', 9797)]\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for text in data:\n",
    "    counter.update(text)\n",
    "print(counter.most_common(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d59f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41570\n",
      "13860\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f27c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr de date de test:  4157\n",
      "Nr de date de validare:  1870\n",
      "Nr de date de antrenare:  35543\n",
      "Nr de date de real-test:  13860\n"
     ]
    }
   ],
   "source": [
    "nr_test = int(10/100 * len(train_data_df))\n",
    "print(\"Nr de date de test: \", nr_test)\n",
    "\n",
    "nr_ramase = len(data) - nr_test\n",
    "nr_valid = int(5/100 * nr_ramase)\n",
    "print(\"Nr de date de validare: \", nr_valid)\n",
    "\n",
    "nr_train = nr_ramase - nr_valid\n",
    "print(\"Nr de date de antrenare: \", nr_train)\n",
    "\n",
    "nr_rtest = int( len(test_data_df))\n",
    "print(\"Nr de date de real-test: \", nr_rtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d4e8262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 41567 41568 41569]\n",
      "[21114 30040 18759 ...  9179 19405 10135]\n"
     ]
    }
   ],
   "source": [
    "# luam niste indici de la 0 la N\n",
    "indici = np.arange(0,len(train_data_df))\n",
    "print(indici)\n",
    "# ii permutam si apoi putem sa-i folosim pentru a amesteca datele\n",
    "np.random.shuffle(indici)\n",
    "print(indici)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "051e3ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr de exemple de real test 13860\n",
      "Nr de exemple de train 35543\n",
      "Nr de exemple de validare 1870\n",
      "Nr de exemple de test 4157\n"
     ]
    }
   ],
   "source": [
    "train_data = data[indici[:nr_train]]\n",
    "train_labels = labels[indici[:nr_train]]\n",
    "\n",
    "valid_data = data[indici[nr_train : nr_train + nr_valid]]\n",
    "valid_labels = labels[indici[nr_train : nr_train + nr_valid]]\n",
    "\n",
    "test_data = data[indici[nr_train + nr_valid: ]]\n",
    "test_labels = labels[indici[nr_train + nr_valid:]]\n",
    "\n",
    "rtest_data = data2[:nr_rtest]\n",
    "\n",
    "\n",
    "\n",
    "print(f'Nr de exemple de real test {len(rtest_data)}')\n",
    "print(f'Nr de exemple de train {len(train_labels)}')\n",
    "print(f'Nr de exemple de validare {len(valid_labels)}')\n",
    "print(f'Nr de exemple de test {len(test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2c8f675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'på': 3, 'støtter': 1, 'ordføreren': 1, 'foreslår': 1, 'parlamentet': 1, 'godkender': 1, 'aftalen': 1, 'langvarige': 1, 'tvister': 1, 'negativ': 1, 'indflydelse': 1, 'erhvervslivet': 1, 'slutforbrugere': 1, 'begge': 1, 'sider': 1, 'middelhavet': 1})\n"
     ]
    }
   ],
   "source": [
    "ctr = Counter(data[9]) # cele mai frecvente cuvinte din primul paragraf \n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909024c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_most_common(how_many, texte_preprocesate):\n",
    "    \"\"\"Functie care returneaza cele mai frecvente cuvinte.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    #TODO:\n",
    "    for text in texte_preprocesate:\n",
    "        counter.update(text)\n",
    "    cuvinte_caracteristice = []\n",
    "    for cuvant, frecventa in counter.most_common(how_many):\n",
    "        if cuvant.strip():\n",
    "            cuvinte_caracteristice.append(cuvant)\n",
    "    return cuvinte_caracteristice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "866f6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_id_word_dicts(cuvinte_caracteristice):\n",
    "    #Dictionarele word2id si id2word garanteaza o ordine pentru cuvintele caracteristice.\n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "    for idx, cuv in enumerate(cuvinte_caracteristice):\n",
    "        word2id[cuv] = idx\n",
    "        id2word[idx] = cuv\n",
    "\n",
    "    return word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff3880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(text_preprocesat, id2word):\n",
    "    #Pentru un text preprocesat dat si un dictionar\n",
    "    #care mapeaza pentru fiecare pozitie ce cuvant corespunde,\n",
    "    #returneaza un vector care reprezinta\n",
    "    #frecventele fiecarui cuvant.\n",
    "    \n",
    "    ctr = Counter(text_preprocesat)\n",
    "    features = np.zeros(len(id2word))\n",
    "    for idx in range(0, len(features)):\n",
    "        cuvant = id2word[idx]\n",
    "        features[idx] = ctr[cuvant]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df1d2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_multi(texte, id2word):\n",
    "    #Pentru un set de texte preprocesate si un dictionar\n",
    "    #care mapeaza pentru fiecare pozitie ce cuvant corespunde,\n",
    "    #returneaza matricea trasaturilor tuturor textelor.\n",
    "    \n",
    "    all_features = []\n",
    "    for text in texte:\n",
    "        all_features.append(featurize(text, id2word))\n",
    "    return np.array(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e85c387",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35543, 3000)\n",
      "(1870, 3000)\n",
      "(4157, 3000)\n",
      "(41570, 3000)\n",
      "(13860, 3000)\n"
     ]
    }
   ],
   "source": [
    "cuvinte_caracteristice = count_most_common(3000,train_data)\n",
    "# print(cuvinte_caracteristice)\n",
    "word2id, id2word = build_id_word_dicts(cuvinte_caracteristice)\n",
    "\n",
    "X_train = featurize_multi(train_data, id2word)\n",
    "X_valid = featurize_multi(valid_data, id2word)\n",
    "X_test = featurize_multi(test_data, id2word)\n",
    "X_data=featurize_multi(data, id2word)\n",
    "#procesarea datelor de real test\n",
    "X_rtest= featurize_multi(rtest_data, id2word)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(X_data.shape)\n",
    "\n",
    "print(X_rtest.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d005f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "# neigh.fit(X_train, train_labels)\n",
    "# vpreds = neigh.predict(X_valid)\n",
    "# tpreds = neigh.predict(X_test)\n",
    "\n",
    "# knpreds = neigh.predict(X_rtest)\n",
    "# print(knpreds)\n",
    "\n",
    "# print(accuracy_score(valid_labels, vpreds))\n",
    "# print(accuracy_score(test_labels, tpreds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e4b5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newlabel= []\n",
    "# for  idx  in knpreds:\n",
    "#     newlabel.append(id2label[idx])\n",
    "# newlabel=np.array(newlabel)\n",
    "# df = pd.DataFrame()\n",
    "# df['id'] = test_data_df.index +1\n",
    "# df['label'] =newlabel\n",
    "# df.to_csv('submission_Kn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6eede41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# clf = GaussianNB()\n",
    "# clf.fit(X_train, train_labels)\n",
    "\n",
    "# vpreds = clf.predict(X_valid)\n",
    "# tpreds = clf.predict(X_test)\n",
    "\n",
    "# bpreds = clf.predict(X_rtest)\n",
    "# print(bpreds)\n",
    "\n",
    "\n",
    "# print(accuracy_score(valid_labels, vpreds))\n",
    "# print(accuracy_score(test_labels, tpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b893319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newlabel= []\n",
    "# for  idx  in bpreds:\n",
    "#     newlabel.append(id2label[idx])\n",
    "# newlabel=np.array(newlabel)\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# df['id'] = test_data_df.index +1\n",
    "# df['label'] =newlabel\n",
    "# df.to_csv('submission_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "812ffd15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "\n",
    "# model = svm.LinearSVC(C=1)\n",
    "\n",
    "# model.fit(X_train, train_labels)\n",
    "# vpreds = model.predict(X_valid)\n",
    "# tpreds = model.predict(X_test)\n",
    "# trainpreds=model.predict(X_train)\n",
    "# svmpreds=model.predict(X_rtest)\n",
    "\n",
    "# print(accuracy_score(valid_labels, vpreds))\n",
    "# print(accuracy_score(test_labels, tpreds))\n",
    "\n",
    "# print(accuracy_score(train_labels,trainpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84a676ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newlabel= []\n",
    "# for  idx  in svmpreds:\n",
    "#     newlabel.append(id2label[idx])\n",
    "# newlabel=np.array(newlabel)\n",
    "# df = pd.DataFrame()\n",
    "# df['id'] = test_data_df.index +1\n",
    "# df['label'] =newlabel\n",
    "# df.to_csv('submission_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "def41fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrr\\.conda\\envs\\LabAI\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 956  398  107]\n",
      " [ 709 3175  774]\n",
      " [ 132  327  531]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrr\\.conda\\envs\\LabAI\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 923  394  142]\n",
      " [ 748 3166  740]\n",
      " [ 146  323  527]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrr\\.conda\\envs\\LabAI\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 951  376  129]\n",
      " [ 679 3176  778]\n",
      " [ 148  353  519]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrr\\.conda\\envs\\LabAI\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 943  426  131]\n",
      " [ 674 3167  724]\n",
      " [ 172  330  541]]\n",
      "[[ 889  335  130]\n",
      " [ 770 3171  776]\n",
      " [ 161  329  547]]\n",
      "accuracy of each fold - [0.6557884371922914, 0.6493177662118441, 0.6535377690251793, 0.6543331457512662, 0.6481429375351716]\n",
      "Avg accuracy : 0.6522240111431505\n",
      "[1 1 1 ... 1 0 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrr\\.conda\\envs\\LabAI\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = X_train\n",
    "y =train_labels\n",
    "\n",
    "k=5\n",
    "kf = KFold(n_splits=k,random_state=None,shuffle=False)\n",
    "\n",
    "\n",
    "model = svm.LinearSVC(C=1)\n",
    "acc_score = []\n",
    "for train_index, test_index in kf.split(X):  \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train,y_train)  \n",
    "    pred_values1 = model.predict(X_test)   \n",
    "    acc = accuracy_score(pred_values1 , y_test)\n",
    "    print(confusion_matrix(pred_values1, y_test))\n",
    "    acc_score.append(acc) \n",
    "    \n",
    "avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "\n",
    "\n",
    "pred_values = model.predict(X_rtest)\n",
    "print(pred_values)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d1881d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabel= []\n",
    "for  idx  in pred_values:\n",
    "    newlabel.append(id2label[idx])\n",
    "newlabel=np.array(newlabel)\n",
    "df = pd.DataFrame()\n",
    "df['id'] = test_data_df.index +1\n",
    "df['label'] =newlabel\n",
    "df.to_csv('submission_k_fold-200.v2.svm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
